\documentclass [a4paper,12pt] {report} 		
\usepackage [utf8] {inputenc} 					 
\usepackage [english,russian] {babel} 			
\usepackage {listings}							
\usepackage {misccorr}						
\usepackage{graphicx}
\setlength{\parindent}{5ex}					

\begin{document}

\begin{center}
{\Large \bfseries \slshape Принцип двух указателей}
\end{center}

Принцип двух указателей актуален, если речь идет о задачах, которые решаются методом полного перебора. Разумеется, такое положение вещей мало кого может устроить – неэффективно, асимптотическая сложность оставляет желать лучшего. 

Посмотрим, что происходит со сложностью алгоритма, на примере следующей задачи – проверим, существует ли подпоследовательность, сумма элементов которой будет больше некоторого константного значения, известного заранее, в последовательности, которую ввели. Что первым делом приходит на ум, если мы собираемся просто решить задачу, не думая о сложности алгоритма? Конечно же, полный перебор. Напишем функцию, проверяющую наличие такой подпоследовательности, учитывая, что изначально нам дано константное значение {\bfseries  D} и сама последовательность {\bfseries  $a_{1}, a_{2}, … , a_{n}$}.

\lstset {language = C++, frame = single}
\begin{lstlisting}
bool exist1(int arr[], int D)
{
    for (int i = 0; i < n; i++)
    {
        s = 0;
        for (int j = i; j < n; j++)
        {
            s += arr[j];
            if (s > D)
            {
                 return 1;
            }
        }
    }
	return 0;
}
\end{lstlisting}

Какова сложность такого алгоритма? Каждый раз осуществляется проверка, сначала {\bfseries n} раз, потом {\bfseries n-1}, и так далее, пока не дойдем до {\bfseries 1}. Соответственно, общее количество шагов – это сумма {\bfseries n} членов арифметической прогрессии, то есть $O(1 + 2 + … + n) = O(\frac {n \cdot (1+n)} {2}) = O(n^2)$. Получается, что сложность квадратичная.

Можно ли как-то оптимизировать процесс? Найти какую-то точку выхода, после которой проверять дальше нет смысла? Давайте представим гипотетическую последовательность, где какие-то элементы положительные, а какие-то – отрицательные. Имеет ли смысл учитывать последовательность, сумма элементов которой отрицательна? Есть вероятность, что сумма потом станет больше известной константы? Но ведь сумма станет ещё больше, если мы исключим эту последовательность. Реализуем оптимизированный алгоритм.

\begin{lstlisting}
bool exist1(int arr[], int D)
{
    for (int i = 0; i < n; i++)
    {
        s = 0;
        for (int j = i; j < n; j++)
        {
            s += arr[j];
            if (s > D)
            {
                 return 1;
            }
            if (s < 0)		//Optimization
            {
                 i = j;
                 break;
            }
        }
    }
	return 0;
}
\end{lstlisting}

Какова же сложность улучшенного алгоритма? По сути дела роль играет только вложенный цикл, в худшем случае количество перебираемых вариантов будет равно {\bfseries n}. Получается, что сложность алгоритма стала $O(n)$, то есть мы получили ощутимый выигрыш.

\end{document}
